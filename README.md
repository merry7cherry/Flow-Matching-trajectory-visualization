# Flow Matching Trajectory Visualisation

This project provides a modular PyTorch implementation for experimenting with
Flow Matching variants on synthetic one-dimensional (1D) and two-dimensional
(2D) datasets. The codebase has been designed to make it straightforward to add
new Flow Matching techniques, model architectures, loss functions and
visualisation routines.

## Implemented variants

* **Standard Flow Matching** using linear interpolation targets.
* **Rectified Flow** trained on trajectories generated by a pre-trained Flow
  Matching model.
* **Variational Flow Matching (VFM)** with a variational autoencoder conditioned
  on the source/target pair and interpolation state.

For each variant, the project produces trajectory plots comparing the analytic
(ground-truth) solution against the learned velocity field for both 1D and 2D
synthetic datasets.

## Project structure

```
flow_matching_trajectory/
├── data/                # Synthetic dataset utilities
├── flows/               # Flow Matching interfaces and variants
├── models/              # Shared neural network modules
├── training/            # Training loop abstractions
├── utils/               # Reusable helpers (seeding, logging, integration)
└── visualization/       # Matplotlib-based plotting helpers
scripts/
└── run_experiments.py   # End-to-end training & visualisation entry point
```

## Getting started

Install the project dependencies (PyTorch and Matplotlib are required) and run

```bash
python scripts/run_experiments.py --output-dir outputs
```

Key command line options:

* `--steps`: number of optimisation steps per variant (default: 3,000).
* `--integration-steps`: number of Euler steps used during trajectory
  simulation (default: 50).
* `--num-trajectories`: number of trajectories visualised per plot (default: 32).
* `--device`: computation device (e.g. `cpu` or `cuda`).

The script writes trajectory plots for each variant into
`<output-dir>/<dimension>/`.

## Extending the project

To implement a new Flow Matching variant, subclass
`flow_matching_trajectory.flows.base.FlowMatchingVariant` and implement
`compute_training_step`, `predict_velocity` and, optionally,
`sample_inference_context`. The training script can then instantiate and train
the new variant without modifications to the rest of the pipeline.

Synthetic datasets can be added by extending `SyntheticPairDataset` or creating a
new dataset module under `flow_matching_trajectory/data/`.
